{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano + Lasagne :: MNIST CNN\n",
    "====================================\n",
    "\n",
    "This is a quick illustration of a Convolutional Neural Network being trained on the MNIST data.\n",
    "\n",
    "( Credit for initially creating this workbook : Eben Olson :: https://github.com/ebenolson/pydata2015 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seed for reproduciblity\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the MNIST data\n",
    "Put it into useful subsets, and show some of it as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('./300_300_data/1.csv', sep=\",\")\n",
    "data2 = pd.read_csv('./300_300_data/2.csv', sep=\",\")\n",
    "data3 = pd.read_csv('./300_300_data/3.csv', sep=\",\")\n",
    "data4 = pd.read_csv('./300_300_data/4.csv', sep=\",\")\n",
    "data=data1.append(data2,ignore_index = True)\n",
    "data=data.append(data3,ignore_index = True)\n",
    "data=data.append(data4,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data[data.columns[0:90000]], data[data.columns[90000]], test_size=0.25, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.as_matrix().astype(np.float)\n",
    "X_val = X_val.as_matrix().astype(np.float)\n",
    "y_train = y_train.as_matrix().astype(np.float)\n",
    "y_val = y_val.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_gen(X, y, N):\n",
    "    while True:\n",
    "        idx = np.random.choice(len(y), N)\n",
    "        yield X[idx].astype('float32'), y[idx].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Network\n",
    "This is a Convolutional Neural Network (CNN), where each 'filter' in a given layer is produced by scanning a small (here 3x3) matrix over the whole of the previous layer (a convolution operation).  These filters can produce effects like : averaging, edge detection, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to reshape from a 1D feature vector to a 1 channel 2D image.\n",
    "# Then we apply 3 convolutional filters with 3x3 kernel size.\n",
    "l_in = lasagne.layers.InputLayer((None, 90000))\n",
    "\n",
    "l_shape = lasagne.layers.ReshapeLayer(l_in, (-1, 1, 300, 300))\n",
    "\n",
    "l_conv = lasagne.layers.Conv2DLayer(l_shape, num_filters=1, filter_size=1, pad=1, stride=(1, 1))\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(l_conv,\n",
    "                                  num_units=2,\n",
    "                                  nonlinearity=lasagne.nonlinearities.softmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Compile and train the network.\n",
    "Accuracy is much better than the single layer network, despite the small number of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0, Train loss 5657.252     (validation : 1882.568) ratio 0.333\n",
      "          Train accuracy 0.558 (validation : 0.500)\n",
      "Epoch  1, Train loss 1418.408     (validation : 2460.667) ratio 1.735\n",
      "          Train accuracy 0.567 (validation : 0.500)\n",
      "Epoch  2, Train loss 1645.487     (validation : 2769.371) ratio 1.683\n",
      "          Train accuracy 0.633 (validation : 0.475)\n",
      "Epoch  3, Train loss 1592.316     (validation : 5850.717) ratio 3.674\n",
      "          Train accuracy 0.683 (validation : 0.525)\n",
      "Epoch  4, Train loss 3713.718     (validation : 5020.209) ratio 1.352\n",
      "          Train accuracy 0.567 (validation : 0.550)\n",
      "Epoch  5, Train loss 2167.960     (validation : 2495.761) ratio 1.151\n",
      "          Train accuracy 0.667 (validation : 0.450)\n",
      "Epoch  6, Train loss 428.090     (validation : 1502.483) ratio 3.510\n",
      "          Train accuracy 0.800 (validation : 0.625)\n",
      "Epoch  7, Train loss 339.264     (validation : 1226.909) ratio 3.616\n",
      "          Train accuracy 0.808 (validation : 0.425)\n",
      "Epoch  8, Train loss 331.377     (validation : 1202.154) ratio 3.628\n",
      "          Train accuracy 0.817 (validation : 0.425)\n",
      "Epoch  9, Train loss 452.749     (validation : 1806.033) ratio 3.989\n",
      "          Train accuracy 0.750 (validation : 0.500)\n",
      "Epoch 10, Train loss 140.383     (validation : 1462.325) ratio 10.417\n",
      "          Train accuracy 0.858 (validation : 0.475)\n",
      "Epoch 11, Train loss 223.569     (validation : 855.113) ratio 3.825\n",
      "          Train accuracy 0.850 (validation : 0.550)\n",
      "Epoch 12, Train loss 52.352     (validation : 1072.059) ratio 20.478\n",
      "          Train accuracy 0.942 (validation : 0.625)\n",
      "Epoch 13, Train loss 109.174     (validation : 907.686) ratio 8.314\n",
      "          Train accuracy 0.875 (validation : 0.475)\n",
      "Epoch 14, Train loss 27.237     (validation : 909.006) ratio 33.374\n",
      "          Train accuracy 0.958 (validation : 0.500)\n",
      "Epoch 15, Train loss 36.086     (validation : 1414.763) ratio 39.206\n",
      "          Train accuracy 0.933 (validation : 0.475)\n",
      "Epoch 16, Train loss 13.059     (validation : 1012.677) ratio 77.544\n",
      "          Train accuracy 0.958 (validation : 0.525)\n",
      "Epoch 17, Train loss 30.042     (validation : 946.729) ratio 31.513\n",
      "          Train accuracy 0.942 (validation : 0.475)\n",
      "Epoch 18, Train loss 64.511     (validation : 1751.481) ratio 27.150\n",
      "          Train accuracy 0.917 (validation : 0.550)\n",
      "Epoch 19, Train loss 2292.931     (validation : 1515.101) ratio 0.661\n",
      "          Train accuracy 0.525 (validation : 0.375)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "X_sym = T.matrix()\n",
    "y_sym = T.ivector()\n",
    "\n",
    "output = lasagne.layers.get_output(l_out, X_sym)\n",
    "pred = output.argmax(-1)\n",
    "\n",
    "loss = T.mean(lasagne.objectives.categorical_crossentropy(output, y_sym))\n",
    "\n",
    "acc = T.mean(T.eq(pred, y_sym))\n",
    "\n",
    "params = lasagne.layers.get_all_params(l_out)\n",
    "grad = T.grad(loss, params)\n",
    "updates = lasagne.updates.adam(grad, params, learning_rate=0.005)\n",
    "\n",
    "f_train = theano.function([X_sym, y_sym], [loss, acc], updates=updates)\n",
    "f_val = theano.function([X_sym, y_sym], [loss, acc])\n",
    "f_predict = theano.function([X_sym], pred)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "N_BATCHES = len(X_train) // BATCH_SIZE\n",
    "N_VAL_BATCHES = len(X_val) // BATCH_SIZE\n",
    "\n",
    "train_batches = batch_gen(X_train, y_train, BATCH_SIZE)\n",
    "val_batches = batch_gen(X_val, y_val, BATCH_SIZE)\n",
    "\n",
    "for epoch in range(20):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for _ in range(N_BATCHES):\n",
    "        X, y = next(train_batches)\n",
    "        loss, acc = f_train(X, y)\n",
    "        train_loss += loss\n",
    "        train_acc += acc\n",
    "    train_loss /= N_BATCHES\n",
    "    train_acc /= N_BATCHES\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    for _ in range(N_VAL_BATCHES):\n",
    "        X, y = next(val_batches)\n",
    "        loss, acc = f_val(X, y)\n",
    "        val_loss += loss\n",
    "        val_acc += acc\n",
    "    val_loss /= N_VAL_BATCHES\n",
    "    val_acc /= N_VAL_BATCHES\n",
    "    \n",
    "    print('Epoch {:2d}, Train loss {:.03f}     (validation : {:.03f}) ratio {:.03f}'.format(\n",
    "            epoch, train_loss, val_loss, val_loss/train_loss))\n",
    "    print('          Train accuracy {:.03f} (validation : {:.03f})'.format(train_acc, val_acc))\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Output after the Convolutional Layer \n",
    "Since the convolutional layer only has 3 filters, we can map these to red, green and blue for easier visualisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered = lasagne.layers.get_output(l_conv, X_sym)\n",
    "f_filter = theano.function([X_sym], filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Bad input argument to theano function with name \"<ipython-input-49-f2c60edf478e>:2\" at index 0 (0-based)', 'TensorType(float32, matrix) cannot store a value of dtype float64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to float32, or 2) set \"allow_input_downcast=True\" when calling \"function\".', array([[ 158.,  146.,  137., ...,  192.,  192.,  193.],\n       [ 255.,  255.,  255., ...,  255.,  255.,  255.]]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-73a45fced112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filter the first few training examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/env/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[1;32m    783\u001b[0m                             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/env/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m'\"function\".'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                             % (self, data.dtype, self.dtype))\n\u001b[0;32m--> 140\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 elif (allow_downcast is None and\n\u001b[1;32m    142\u001b[0m                         \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Bad input argument to theano function with name \"<ipython-input-49-f2c60edf478e>:2\" at index 0 (0-based)', 'TensorType(float32, matrix) cannot store a value of dtype float64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to float32, or 2) set \"allow_input_downcast=True\" when calling \"function\".', array([[ 158.,  146.,  137., ...,  192.,  192.,  193.],\n       [ 255.,  255.,  255., ...,  255.,  255.,  255.]]))"
     ]
    }
   ],
   "source": [
    "# Filter the first few training examples\n",
    "im = f_filter(X_train[:2])\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3ab8ff2e8abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Rearrange dimension so we can plot the result as RGB images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'im' is not defined"
     ]
    }
   ],
   "source": [
    "# Rearrange dimension so we can plot the result as RGB images\n",
    "im = np.rollaxis(np.rollaxis(im, 3, 1), 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each filter detected different features in the images, i.e. horizontal / diagonal / vertical segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(im[i], interpolation='nearest')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
